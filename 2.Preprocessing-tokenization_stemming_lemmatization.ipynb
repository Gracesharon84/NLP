{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE-PROCESSING:TOKENIZATION, STEMMING, LEMMATIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Simple Tokenization and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Words: ['run', 'runner', 'run', 'in', 'a', 'race', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "text = \"Running runners run in a race.\"\n",
    "tokens = word_tokenize(text)\n",
    "stemmer = PorterStemmer()\n",
    "stemmed = [stemmer.stem(token) for token in tokens]\n",
    "print(\"Stemmed Words:\", stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Advanced Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized Words: ['The', 'striped', 'bat', 'be', 'hang', 'on', 'their', 'foot', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import  wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag,word_tokenize\n",
    "text=\"The striped bats are hanging on their feet.\"\n",
    "tokens=word_tokenize(text)\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "#functions to get WordNet POS\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "lemmatized=[lemmatizer.lemmatize(w, get_wordnet_pos(t))for w,t in pos_tag(tokens)]\n",
    "print(\"Lemmatized Words:\",lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. LOVINS STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stemming in c:\\programdata\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Original words:\n",
      " ['Love', 'looks', 'not', 'with', 'the', 'eyes', 'but', 'with', 'the', 'mind', ',', 'and', 'therefore', 'is', 'winged', 'Cupid', 'painted', 'blind', '.']\n",
      "Stemmed words:\n",
      " ['Lov', 'look', 'not', 'with', 'th', 'ey', 'but', 'with', 'th', 'mind', ',', 'and', 'therefor', 'is', 'wing', 'Cupid', 'paint', 'blind', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "!pip install stemming\n",
    "from stemming.lovins import stem\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"Love looks not with the eyes but with the mind, and therefore is winged Cupid painted blind.\"\n",
    "words = word_tokenize(text)\n",
    "stemmed_words = [stem(word) for word in words]\n",
    "\n",
    "print(\"Original words:\\n\", words)\n",
    "print(\"Stemmed words:\\n\", stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. SNOWBALL STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original words: ['running', 'jumped', 'happily', 'quickly', 'foxes']\n",
      "Stemmed words: ['run', 'jump', 'happili', 'quick', 'fox']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "words_to_stem = ['running', 'jumped', 'happily', 'quickly', 'foxes']\n",
    "stemmed_words = [stemmer.stem(word) for word in words_to_stem]\n",
    "print(\"Original words:\", words_to_stem)\n",
    "print(\"Stemmed words:\", stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. REGEXP STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['runn', 'runner', 'ran']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer  \n",
    "rs = RegexpStemmer('ing$|s$|ed$') \n",
    "words = [\"running\", \"runner\", \"ran\"] \n",
    "stemmed_words = [rs.stem(word) for word in words] \n",
    "print(stemmed_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. LANCASTER STEMMING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'run', 'ran']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer  \n",
    "ls = LancasterStemmer() \n",
    "words = [\"running\", \"runner\", \"ran\"] \n",
    "stemmed_words = [ls.stem(word) for word in words] \n",
    "print(stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. DOWSON STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DawsonStemmer' from 'nltk.stem' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\stem\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-81f64d751298>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDawsonStemmer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDawsonStemmer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"running\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"runner\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ran\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mstemmed_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstemmed_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'DawsonStemmer' from 'nltk.stem' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\stem\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from nltk.stem import DawsonStemmer \n",
    "ds = DawsonStemmer() \n",
    "words = [\"running\", \"runner\", \"ran\"]\n",
    "stemmed_words = [ds.stem(word) for word in words]\n",
    "print(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
